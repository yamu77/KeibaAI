{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パッケージ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import os, time\n",
    "from tqdm import tqdm\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from abc import ABC, abstractmethod\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レース結果を整形するクラス(仮)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceResultsProcessor_:\n",
    "    \"\"\"レース結果をデータを整形する\"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        self.results_raw = pd.read_pickle(path)\n",
    "        self.results_processed = pd.read_pickle(path)\n",
    "        # データの0埋めを行う\n",
    "        self.results_processed.fillna(0, inplace=True)\n",
    "        # 馬体重のカラムについては「0(0)」で埋める\n",
    "        self.results_processed[\"馬体重\"].replace(0, \"0(0)\", inplace=True)\n",
    "\n",
    "    def drop_columns(self, columns: [str]) -> None:\n",
    "        \"\"\"不要なカラムを削除\"\"\"\n",
    "        self.results_processed = self.results_processed.drop(columns=columns)\n",
    "\n",
    "    def divide_weight_gender(self):\n",
    "        \"\"\"馬の性齢と馬体重を分割する\"\"\"\n",
    "        self.results_processed[\"性別\"] = self.results_processed[\"性齢\"].str[0]\n",
    "        self.results_processed[\"年齢\"] = self.results_processed[\"性齢\"].str[1:]\n",
    "        self.results_processed[\"体重\"] = self.results_processed[\"馬体重\"].replace(\n",
    "            to_replace=r\"(\\d+).*\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "        self.results_processed[\"増減\"] = self.results_processed[\"馬体重\"].replace(\n",
    "            to_replace=r\"\\d+\\(\\+{0,1}([-]{0,1}\\d+)\\)\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "\n",
    "    def transform_rank(self):\n",
    "        self.results_processed[\"3着以内\"] = self.results_processed[\"着順\"].apply(\n",
    "            lambda x: 1 if isinstance(x, int) and x <= 3 else 0\n",
    "        )\n",
    "\n",
    "    def transform_date(self, date: str):\n",
    "        \"\"\"日付を変換して、その年の1月1日からの日数を計算する\"\"\"\n",
    "        # 日付の形式を変換\n",
    "        date_converted = datetime.datetime.strptime(date, \"%Y年%m月%d日\")\n",
    "        # その年の1月1日を計算\n",
    "        base_date = datetime.datetime(date_converted.year, 1, 1)\n",
    "        # 日数の差を計算\n",
    "        return (date_converted - base_date).days\n",
    "\n",
    "    def __extraction_drop_columns(\n",
    "        self, df: pd.DataFrame, columns: [str]\n",
    "    ) -> (pd.DataFrame, pd.DataFrame):\n",
    "        df_extraction = df.loc[:, columns]\n",
    "        df_dropped = df.drop(columns=columns)\n",
    "        return df_extraction, df_dropped\n",
    "\n",
    "    def make_race_infos(self):\n",
    "        \"\"\"データをレースの情報、出走馬の情報、過去成績の3つに分ける\"\"\"\n",
    "        drop_columns = [\n",
    "            \"馬名\",\n",
    "            \"性齢\",\n",
    "            \"騎手\",\n",
    "            \"タイム\",\n",
    "            \"着差\",\n",
    "            \"人気\",\n",
    "            \"調教師\",\n",
    "            \"単勝\",\n",
    "            \"jockey_id\",\n",
    "            \"馬体重\",\n",
    "        ]\n",
    "        race_info_columns = [\n",
    "            \"date\",\n",
    "            \"round\",\n",
    "            \"course_length\",\n",
    "            \"course_type\",\n",
    "            \"course_way\",\n",
    "            \"weather\",\n",
    "            \"state_grass\",\n",
    "            \"state_dirt\",\n",
    "            \"place\",\n",
    "            \"class\",\n",
    "        ]\n",
    "        self.divide_weight_gender()\n",
    "        self.transform_rank()\n",
    "        self.drop_columns(drop_columns)\n",
    "        self.race_info, self.horse_info = self.__extraction_drop_columns(\n",
    "            self.results_processed, race_info_columns\n",
    "        )\n",
    "        self.horse_results, self.horse_info = self.__extraction_drop_columns(\n",
    "            self.horse_info, [\"horse_id\"]\n",
    "        )\n",
    "\n",
    "        self.race_info = self.race_info.loc[[0], :]\n",
    "        self.race_info[\"date\"] = self.transform_date(self.race_info.loc[0, \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>round</th>\n",
       "      <th>course_length</th>\n",
       "      <th>course_type</th>\n",
       "      <th>course_way</th>\n",
       "      <th>weather</th>\n",
       "      <th>state_grass</th>\n",
       "      <th>state_dirt</th>\n",
       "      <th>place</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>ダ</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>無</td>\n",
       "      <td>良</td>\n",
       "      <td>札幌</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date round course_length course_type course_way weather state_grass  \\\n",
       "0   239     7          1000           ダ          右       晴           無   \n",
       "\n",
       "  state_dirt place class  \n",
       "0          良    札幌    1勝  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = RaceResultsProcessor_(\"../Raw-Data/Race-Results/2022/01020607.pkl\")\n",
    "test.make_race_infos()\n",
    "\n",
    "test.race_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3456/3456 [00:29<00:00, 115.51it/s]\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../Raw-Data/Race-Results/2022/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "df_list = []\n",
    "for i in tqdm(dir_list):\n",
    "    result = RaceResultsProcessor_(f\"{results_path}{i}\")\n",
    "    result.make_race_infos()\n",
    "    df_list.append(result.race_info)\n",
    "\n",
    "df_integration = pd.concat(df_list)\n",
    "df_integration.to_pickle(\"../tmp/race-infos.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'round', 'course_length', 'course_type', 'course_way',\n",
      "       'weather', 'state_grass', 'state_dirt', 'place', 'class'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>round</th>\n",
       "      <th>course_length</th>\n",
       "      <th>course_type</th>\n",
       "      <th>course_way</th>\n",
       "      <th>weather</th>\n",
       "      <th>state_grass</th>\n",
       "      <th>state_dirt</th>\n",
       "      <th>place</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>曇</td>\n",
       "      <td>重</td>\n",
       "      <td>良</td>\n",
       "      <td>札幌</td>\n",
       "      <td>未勝利</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>1700</td>\n",
       "      <td>ダ</td>\n",
       "      <td>右</td>\n",
       "      <td>曇</td>\n",
       "      <td>良</td>\n",
       "      <td>重</td>\n",
       "      <td>札幌</td>\n",
       "      <td>未勝利</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>曇</td>\n",
       "      <td>重</td>\n",
       "      <td>良</td>\n",
       "      <td>札幌</td>\n",
       "      <td>未勝利</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>曇</td>\n",
       "      <td>重</td>\n",
       "      <td>良</td>\n",
       "      <td>札幌</td>\n",
       "      <td>未勝利</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "      <td>1700</td>\n",
       "      <td>ダ</td>\n",
       "      <td>右</td>\n",
       "      <td>曇</td>\n",
       "      <td>良</td>\n",
       "      <td>重</td>\n",
       "      <td>札幌</td>\n",
       "      <td>新馬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>良</td>\n",
       "      <td>良</td>\n",
       "      <td>小倉</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>良</td>\n",
       "      <td>良</td>\n",
       "      <td>小倉</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>良</td>\n",
       "      <td>重</td>\n",
       "      <td>小倉</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>良</td>\n",
       "      <td>稍</td>\n",
       "      <td>小倉</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "      <td>芝</td>\n",
       "      <td>右</td>\n",
       "      <td>晴</td>\n",
       "      <td>良</td>\n",
       "      <td>不</td>\n",
       "      <td>小倉</td>\n",
       "      <td>1勝</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3461 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    date round course_length course_type course_way weather state_grass  \\\n",
       "0    203     1          1800           芝          右       曇           重   \n",
       "0    203     2          1700           ダ          右       曇           良   \n",
       "0    203     3          1500           芝          右       曇           重   \n",
       "0    203     4          1200           芝          右       曇           重   \n",
       "0    203     5          1700           ダ          右       曇           良   \n",
       "..   ...   ...           ...         ...        ...     ...         ...   \n",
       "0    246    12          2600           芝          右       晴           良   \n",
       "0    246    12          2600           芝          右       晴           良   \n",
       "0    246    12          2600           芝          右       晴           良   \n",
       "0    246    12          2600           芝          右       晴           良   \n",
       "0    246    12          2600           芝          右       晴           良   \n",
       "\n",
       "   state_dirt place class  \n",
       "0           良    札幌   未勝利  \n",
       "0           重    札幌   未勝利  \n",
       "0           良    札幌   未勝利  \n",
       "0           良    札幌   未勝利  \n",
       "0           重    札幌    新馬  \n",
       "..        ...   ...   ...  \n",
       "0           良    小倉    1勝  \n",
       "0           良    小倉    1勝  \n",
       "0           重    小倉    1勝  \n",
       "0           稍    小倉    1勝  \n",
       "0           不    小倉    1勝  \n",
       "\n",
       "[3461 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_integration.columns)\n",
    "df_integration[df_integration[\"course_type\"] == \"障\"]\n",
    "\"\"\"\n",
    "無              1693\n",
    "良              1385\n",
    "重               359\n",
    "稍                18\n",
    "不                 1\n",
    "\"\"\"\n",
    "# 足りないデータを追加\n",
    "tmps = []\n",
    "tmps.append(df_integration)\n",
    "for i in [\"無\", \"良\", \"重\", \"稍\", \"不\"]:\n",
    "    tmp = df_integration[-1:].copy()\n",
    "    tmp[\"state_dirt\"] = i\n",
    "    tmps.append(tmp)\n",
    "\n",
    "df_integration_new = pd.concat(tmps)\n",
    "# いらないデータを置換\n",
    "df_integration_new[\"course_way\"].replace(\"無\", \"右\", inplace=True)\n",
    "df_integration_new[\"state_grass\"].replace(\"無\", \"良\", inplace=True)\n",
    "df_integration_new[\"state_dirt\"].replace(\"無\", \"良\", inplace=True)\n",
    "df_integration_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'round', 'course_length', 'course_type_芝', 'course_type_ダ',\n",
       "       'course_type_障', 'course_way_右', 'course_way_左', 'course_way_直',\n",
       "       'weather_曇', 'weather_晴', 'weather_雨', 'weather_雪', 'state_grass_重',\n",
       "       'state_grass_良', 'state_grass_稍', 'state_grass_不', 'state_dirt_良',\n",
       "       'state_dirt_重', 'state_dirt_稍', 'state_dirt_不', 'place_札幌', 'place_函館',\n",
       "       'place_福島', 'place_新潟', 'place_東京', 'place_中山', 'place_中京', 'place_阪神',\n",
       "       'place_小倉', 'class_未勝利', 'class_新馬', 'class_1勝', 'class_2勝', 'class_3勝',\n",
       "       'class_G3', 'class_L', 'class_オープン', 'class_G2', 'class_G1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ワンホットエンコーディングを行うカラムを指定\n",
    "columns_to_encode = [\n",
    "    \"course_type\",\n",
    "    \"course_way\",\n",
    "    \"weather\",\n",
    "    \"state_grass\",\n",
    "    \"state_dirt\",\n",
    "    \"place\",\n",
    "    \"class\",\n",
    "]\n",
    "\n",
    "# エンコーダーのインスタンスを作成\n",
    "encoder = ce.OneHotEncoder(\n",
    "    cols=columns_to_encode, use_cat_names=True, handle_unknown=\"value\"\n",
    ")\n",
    "\n",
    "# ワンホットエンコーディングを実行\n",
    "df_integration_encoded = encoder.fit_transform(df_integration_new)\n",
    "with open(\"../models/race_info_encoder.pickle\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "df_integration_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出走馬情報の標準化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceResults:\n",
    "    \"\"\"レース結果をデータを整形する\"\"\"\n",
    "\n",
    "    with open(\"../models/race_info_encoder.pickle\", \"rb\") as f:\n",
    "        encoder = pickle.load(f)\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        self.results_raw = pd.read_pickle(path)\n",
    "        self.results_processed = pd.read_pickle(path)\n",
    "        # データの0埋めを行う\n",
    "        self.results_processed.fillna(0, inplace=True)\n",
    "        # 馬体重のカラムについては「0(0)」で埋める\n",
    "        self.results_processed[\"馬体重\"].replace(0, \"0(0)\", inplace=True)\n",
    "        with open(\"../models/race_info_encoder.pickle\", \"rb\") as f:\n",
    "            self.encoder = pickle.load(f)\n",
    "\n",
    "    def read_df(path: str) -> pd.DataFrame:\n",
    "        if not isinstance(path, str):\n",
    "            raise TypeError(\n",
    "                f'\"path\" argument is expected to be of type str, got {type(path).__name__} instead'\n",
    "            )\n",
    "        results_processed = pd.read_pickle(path)\n",
    "        return results_processed\n",
    "\n",
    "    def divide_weight_gender(df_raw: pd.DataFrame):\n",
    "        \"\"\"馬の性齢と馬体重を分割する\"\"\"\n",
    "        df = df_raw.copy()\n",
    "        gender = df[\"性齢\"].str[0]\n",
    "        df[\"牡\"] = gender.map(lambda x: 1 if x == \"牡\" else 0)\n",
    "        df[\"牝\"] = gender.map(lambda x: 1 if x == \"牝\" else 0)\n",
    "        df[\"セ\"] = gender.map(lambda x: 1 if x == \"セ\" else 0)\n",
    "        df[\"年齢\"] = df[\"性齢\"].str[1:]\n",
    "        df[\"体重\"] = df[\"馬体重\"].replace(\n",
    "            to_replace=r\"(\\d+).*\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "        df[\"増減\"] = df[\"馬体重\"].replace(\n",
    "            to_replace=r\"\\d+\\(\\+{0,1}([-]{0,1}\\d+)\\)\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def transform_rank(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df_raw.copy()\n",
    "        df[\"3着以内\"] = df[\"着順\"].apply(\n",
    "            lambda x: 1 if isinstance(x, int) and x <= 3 else 0\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def drop_columns(df_raw: pd.DataFrame, columns: [str]) -> pd.DataFrame:\n",
    "        \"\"\"不要なカラムを削除\"\"\"\n",
    "        df = df_raw.drop(columns=columns)\n",
    "        return df\n",
    "\n",
    "    def transform_date(date: str):\n",
    "        \"\"\"日付を変換して、その年の1月1日からの週数を計算する\"\"\"\n",
    "        # 日付の形式を変換\n",
    "        date_converted = datetime.datetime.strptime(date, \"%Y年%m月%d日\")\n",
    "        # その年の1月1日を計算\n",
    "        base_date = datetime.datetime(date_converted.year, 1, 1)\n",
    "        # 週数の差を計算\n",
    "        return (date_converted - base_date).days // 7\n",
    "\n",
    "    def extraction_drop_columns(\n",
    "        df: pd.DataFrame, columns: [str]\n",
    "    ) -> (pd.DataFrame, pd.DataFrame):\n",
    "        df_extraction = df.loc[:, columns]\n",
    "        df_dropped = df.drop(columns=columns)\n",
    "        return df_extraction, df_dropped\n",
    "\n",
    "    @classmethod\n",
    "    def adapt_race_info(cls, df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df_raw.loc[[0], :]\n",
    "        df[\"date\"] = cls.transform_date(df.loc[0, \"date\"])\n",
    "        df[\"course_length\"] = float(df.loc[0, \"course_length\"]) / 100\n",
    "\n",
    "        df = cls.encoder.transform(df)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def make_infos(cls, path: str) -> {}:\n",
    "        drop_columns = [\n",
    "            \"馬名\",\n",
    "            \"性齢\",\n",
    "            \"騎手\",\n",
    "            \"タイム\",\n",
    "            \"着差\",\n",
    "            \"人気\",\n",
    "            \"調教師\",\n",
    "            \"単勝\",\n",
    "            \"jockey_id\",\n",
    "            \"馬体重\",\n",
    "            \"着順\",\n",
    "        ]\n",
    "        race_info_columns = [\n",
    "            \"date\",\n",
    "            \"round\",\n",
    "            \"course_length\",\n",
    "            \"course_type\",\n",
    "            \"course_way\",\n",
    "            \"weather\",\n",
    "            \"state_grass\",\n",
    "            \"state_dirt\",\n",
    "            \"place\",\n",
    "            \"class\",\n",
    "        ]\n",
    "        df = cls.read_df(path)\n",
    "        # データの0埋めを行う\n",
    "        df = df.fillna(0)\n",
    "        # 馬体重のカラムについては「0(0)」で埋める\n",
    "        df[\"馬体重\"].replace(0, \"0(0)\", inplace=True)\n",
    "        df[\"馬体重\"].replace(\"計不\", \"0(0)\", inplace=True)\n",
    "        df = cls.divide_weight_gender(df)\n",
    "        df = cls.transform_rank(df)\n",
    "        df = cls.drop_columns(df, drop_columns)\n",
    "        race_info, horse_info = cls.extraction_drop_columns(df, race_info_columns)\n",
    "        horse_id, horse_info = cls.extraction_drop_columns(horse_info, [\"horse_id\"])\n",
    "\n",
    "        # 標準化等の変換\n",
    "        race_info = cls.adapt_race_info(race_info)\n",
    "        return {\n",
    "            \"race\": race_info,\n",
    "            \"horse\": horse_info,\n",
    "            \"ids\": list(horse_id.iloc[:, 0].values),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>性別</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>増減</th>\n",
       "      <th>3着以内</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>牡</td>\n",
       "      <td>3</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>476</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>セ</td>\n",
       "      <td>4</td>\n",
       "      <td>478</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>牝</td>\n",
       "      <td>5</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>牡</td>\n",
       "      <td>4</td>\n",
       "      <td>538</td>\n",
       "      <td>-18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>牡</td>\n",
       "      <td>5</td>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>442</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>牡</td>\n",
       "      <td>3</td>\n",
       "      <td>510</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>514</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>セ</td>\n",
       "      <td>5</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>牡</td>\n",
       "      <td>4</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    着順  枠番  馬番  斤量 性別 年齢   体重   増減  3着以内\n",
       "0    6   1   1  51  牡  3  486    4     0\n",
       "1    9   2   2  52  牝  3  476    6     0\n",
       "2    7   3   3  54  セ  4  478    8     0\n",
       "3   11   4   4  55  牝  5  470    6     0\n",
       "4    3   5   5  55  牡  4  538  -18     1\n",
       "5    8   5   6  57  牡  5  498    2     0\n",
       "6    4   6   7  51  牝  3  442    0     0\n",
       "7    1   6   8  52  牝  3  442   10     1\n",
       "8    5   7   9  53  牡  3  510    4     0\n",
       "9   12   7  10  52  牝  3  514    2     0\n",
       "10   2   8  11  55  セ  5  490    0     1\n",
       "11  10   8  12  57  牡  4  486    4     0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = RaceResults.make_infos(\"../Raw-Data/Race-Results/2022/01020607.pkl\")\n",
    "test[\"horse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../Raw-Data/Race-Results/2022/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "df_list = []\n",
    "for i in tqdm(dir_list):\n",
    "    result = RaceResults.make_infos(f\"{results_path}{i}\")\n",
    "    df_list.append(result[\"horse\"])\n",
    "\n",
    "df_integration = pd.concat(df_list)\n",
    "df_integration.to_pickle(\"../tmp/horse-info.pkl\")\n",
    "df_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../tmp/horse-info.pkl\")\n",
    "scaler = StandardScaler()\n",
    "# 標準化したいカラムを指定\n",
    "columns_to_scale = [\"体重\", \"増減\"]\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/horse_info_scaler.pickle\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットクラス\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, hidden_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # div_termの計算\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_dim, 2).float() * (-math.log(10000.0) / hidden_dim)\n",
    "        )\n",
    "\n",
    "        # position * div_term のサイズ調整\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, nheads, nlayers, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            hidden_dim, nheads, hidden_dim, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.input_linear(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, input_dim, nheads, nlayers, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout)\n",
    "        decoder_layers = nn.TransformerDecoderLayer(\n",
    "            hidden_dim, nheads, hidden_dim, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_decoder(src, src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, nheads, nlayers, dropout=0.1):\n",
    "        super(TransformerVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, nheads, nlayers, dropout)\n",
    "        self.decoder = Decoder(hidden_dim, input_dim, nheads, nlayers, dropout)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_out = nn.Linear(latent_dim, hidden_dim)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, src):\n",
    "        encoded = self.encoder(src)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        log_var = self.fc_log_var(encoded)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        z = self.fc_out(z)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, log_var\n",
    "\n",
    "    def get_latent_val(self, src):\n",
    "        encoded = self.encoder(src)\n",
    "        val = self.fc_mu(encoded)\n",
    "        return val\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    def __init__(self, path: str, device=None) -> None:\n",
    "        \"\"\"VAEモデルを推論モードで立ち上げる\n",
    "\n",
    "        Args:\n",
    "            str: 保存したモデルのパス\n",
    "            device (_type_, optional): cpuでモデルを使う場合は\"cpu\"を入れる. デフォルトはNone.\n",
    "        \"\"\"\n",
    "        self.model = TransformerVAE(\n",
    "            input_dim=67,\n",
    "            hidden_dim=64,\n",
    "            latent_dim=4,\n",
    "            nheads=8,\n",
    "            nlayers=8,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        if device == \"cpu\":\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            )\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "        self.model.eval()\n",
    "\n",
    "    def transform(self, df_raw: pd.DataFrame) -> torch.Tensor:\n",
    "        \"\"\"VAEによる変換をする\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象のデータフレーム\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 変換し１次元にしたデータ\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        df = df.iloc[:].astype(\"float32\")\n",
    "        # データフレームをテンソルに変換\n",
    "        data = torch.tensor(df.values, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded = self.model.get_latent_val(data)\n",
    "        return torch.flatten(encoded)\n",
    "\n",
    "    def process(self, dfs: list[pd.DataFrame]):\n",
    "        processed_data = []\n",
    "        for i in dfs:\n",
    "            data_transform = self.transform(i)\n",
    "            processed_data.append(data_transform)\n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 成績の処理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スーパークラス\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def read_results(path: str) -> pd.DataFrame:\n",
    "        if isinstance(path, str):\n",
    "            return pd.read_pickle(path)\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                f'\"path\" argument is expected to be of type str, got {type(path).__name__} instead'\n",
    "            )\n",
    "\n",
    "    def arrange_result(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"データフレームの欠損値の0埋めとカラム名の空白を消す\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 処理後のデータフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        # 欠損値を0埋め\n",
    "        df = df.fillna(0)\n",
    "        # カラム名の空白を削除\n",
    "        df.columns = df.columns.str.replace(\" \", \"\")\n",
    "        df[\"日付\"] = pd.to_datetime(df[\"日付\"], format=\"%Y/%m/%d\")\n",
    "        return df\n",
    "\n",
    "    def remove_str(x: any) -> str:\n",
    "        \"\"\"文字列から数値だけを取り出す\n",
    "\n",
    "        Args:\n",
    "            x (any): 処理する文字列\n",
    "\n",
    "        Returns:\n",
    "            str: 処理後の文字列（数字がなかった場合は\"0\"を返す）\n",
    "        \"\"\"\n",
    "        x_str = str(x)\n",
    "        is_contain_num = re.search(r\"\\d+\", x_str)\n",
    "        if is_contain_num:\n",
    "            return is_contain_num.group()\n",
    "        else:\n",
    "            return \"0\"\n",
    "\n",
    "    def convert_date(x: str) -> int:\n",
    "        \"\"\"日付をその年の1/1から数えた週数に変換する\n",
    "\n",
    "        Args:\n",
    "            x (str): 日付\n",
    "\n",
    "        Returns:\n",
    "            int: 週数\n",
    "        \"\"\"\n",
    "\n",
    "        # その年の1月1日を計算\n",
    "        base_date = datetime.datetime(x.year, 1, 1)\n",
    "        # 週数の差を計算\n",
    "        return (x - base_date).days // 7\n",
    "\n",
    "    def transform_held(held: str) -> str:\n",
    "        \"\"\"開催場所の文字列から不要な文字を取り除く。中央以外は\"その他\"にする\n",
    "\n",
    "        Args:\n",
    "            held (str): 処理する文字列\n",
    "\n",
    "        Returns:\n",
    "            str: 処理後の文字列\n",
    "        \"\"\"\n",
    "        trim_held = re.sub(r\"\\d*\", \"\", held)\n",
    "        if not trim_held in [\n",
    "            \"東京\",\n",
    "            \"中山\",\n",
    "            \"中京\",\n",
    "            \"阪神\",\n",
    "            \"札幌\",\n",
    "            \"函館\",\n",
    "            \"福島\",\n",
    "            \"新潟\",\n",
    "            \"京都\",\n",
    "            \"小倉\",\n",
    "        ]:\n",
    "            return \"その他\"\n",
    "        return trim_held\n",
    "\n",
    "    def transform_race_name(race: str) -> str:\n",
    "        \"\"\"レースのクラス分けをする。当てはまらないものは\"その他\"にする\n",
    "\n",
    "        Args:\n",
    "            race (str): レースクラスの文字列\n",
    "\n",
    "        Returns:\n",
    "            str: 処理後文字列\n",
    "        \"\"\"\n",
    "\n",
    "        if re.search(r\".*(新馬|未勝利|1勝|2勝|3勝|OP|G1|G2|G3|L).*\", race):\n",
    "            transform_name = re.sub(\n",
    "                r\".*(新馬|未勝利|1勝|2勝|3勝|OP|G1|G2|G3|L).*\", r\"\\1\", race\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            transform_name = \"その他\"\n",
    "        return transform_name\n",
    "\n",
    "    def extract_addition(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        weight = df[\"馬体重\"]\n",
    "\n",
    "        addition = weight.map(lambda x: re.sub(r\".*\\(([+-]\\d{1,3}|0)\\).*\", r\"\\1\", x))\n",
    "        addition = addition.map(lambda x: re.sub(r\"\\+\", \"\", x))\n",
    "        return addition\n",
    "\n",
    "    def drop_columns(df: pd.DataFrame, columns: [str]) -> pd.DataFrame:\n",
    "        df_processed = df.drop(\n",
    "            columns,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return df_processed\n",
    "\n",
    "    def divide_corse(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_divided = df\n",
    "\n",
    "        df_divided[\"コース\"] = df_divided[\"距離\"].map(lambda x: x[0])\n",
    "        df_divided[\"距離\"] = df_divided[\"距離\"].map(lambda x: int(x[1:]) / 100)\n",
    "        return df_divided\n",
    "\n",
    "    def divide_horse_weight(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"馬体重と増減を分ける\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): 対象のデータフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 処理後のデータフレーム\n",
    "        \"\"\"\n",
    "        df_divided = df\n",
    "\n",
    "        df_divided[\"馬体重\"] = df_divided[\"馬体重\"].map(\n",
    "            lambda x: x.replace(\"計不\", \"0(0)\")\n",
    "        )\n",
    "        weight = df_divided[\"馬体重\"]\n",
    "        weight_addition = weight.map(\n",
    "            lambda x: re.sub(r\".*\\(([+-]\\d{1,3}|0)\\).*\", r\"\\1\", x)\n",
    "        )\n",
    "        weight_addition = weight_addition.map(lambda x: re.sub(r\"\\+\", \"\", x))\n",
    "        df_divided[\"増減\"] = weight_addition\n",
    "        df_divided[\"馬体重\"] = df_divided[\"馬体重\"].map(\n",
    "            lambda x: re.sub(r\"\\([+-]*\\d+\\)\", \"\", x)\n",
    "        )\n",
    "\n",
    "        return df_divided\n",
    "\n",
    "    def add_rows(df_raw: pd.DataFrame, rows: int) -> pd.DataFrame:\n",
    "        \"\"\"行の補填をする\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "            rows (int): 補填する行数\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 処理後のデータフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                df,\n",
    "                pd.DataFrame(np.zeros((rows, len(df.columns))), columns=df.columns),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 親成績の処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedigreeResults(ResultProcessor):\n",
    "    with open(\"../models/pedigree_pca.pickle\", \"rb\") as f:\n",
    "        pca = pickle.load(f)\n",
    "\n",
    "    def arrange_result(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"データフレームの欠損値の0埋めとカラム名の空白を消す\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 処理後のデータフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        # 欠損値を0埋め\n",
    "        df = df.fillna(0)\n",
    "        # カラム名の空白を削除\n",
    "        df.columns = df.columns.str.replace(\" \", \"\")\n",
    "        # df[\"日付\"] = pd.to_datetime(df[\"日付\"], format=\"%Y/%m/%d\")\n",
    "        return df\n",
    "\n",
    "    def read_results(path: str) -> [pd.DataFrame]:\n",
    "        if isinstance(path, str):\n",
    "            ped_results = []\n",
    "            with open(path, \"rb\") as f:\n",
    "                peds = pickle.load(f)\n",
    "            for i in peds:\n",
    "                df = pd.read_pickle(f\"../Raw-Data/Pedigree-Results/{i}.pkl\")\n",
    "                ped_results.append(df)\n",
    "            return ped_results\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                f'\"path\" argument is expected to be of type str, got {type(path).__name__} instead'\n",
    "            )\n",
    "\n",
    "    def transform_race_length(length: str | int | float) -> str:\n",
    "        if isinstance(length, str):\n",
    "            length = int(length)\n",
    "\n",
    "        elif math.isnan(length):\n",
    "            length = 0\n",
    "        elif not (isinstance(length, int) or isinstance(length, float)):\n",
    "            raise TypeError(\n",
    "                f'\"length\" argument is expected to be of type int or str, got {type(length).__name__} instead. The value is {length}'\n",
    "            )\n",
    "        match length:\n",
    "            case length if length < 1000:\n",
    "                return \"不明\"\n",
    "            case length if length <= 1300:\n",
    "                return \"S\"\n",
    "            case length if length <= 1899:\n",
    "                return \"M\"\n",
    "            case length if length <= 2100:\n",
    "                return \"I\"\n",
    "            case length if length <= 2700:\n",
    "                return \"L\"\n",
    "            case length if length > 2700:\n",
    "                return \"E\"\n",
    "\n",
    "    def delete_invalid_race(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.drop(index=df[df[\"着順\"] == 0].index)\n",
    "        df = df.drop(index=df[df[\"着順\"] == \"0\"].index)\n",
    "        return df\n",
    "\n",
    "    def divide_corse(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_divided = df\n",
    "        match_str = r\"[芝ダ障]{0,1}\\d{1,4}\"\n",
    "        if len(df_divided) <= 1:\n",
    "            df_divided[\"コース\"] = 0\n",
    "            df_divided[\"距離\"] = 0\n",
    "            return df_divided\n",
    "        df_divided[\"コース\"] = df_divided[\"距離\"].map(\n",
    "            lambda x: x[0] if isinstance(x, str) else 0\n",
    "        )\n",
    "        df_divided[\"距離\"] = df_divided[\"距離\"].map(\n",
    "            lambda x: int(x[1:]) if isinstance(x, str) else 0\n",
    "        )\n",
    "        return df_divided\n",
    "\n",
    "    def totalling_result(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"成績データを競馬場や馬場、着順等で分けて集計する\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): 成績データ（時系列順）\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 集計した成績データ\n",
    "        \"\"\"\n",
    "        df_tmp: pd.DataFrame = pd.read_pickle(\n",
    "            \"../template/pedigree_results_template.pcl\"\n",
    "        )\n",
    "        for _, row in df.iterrows():\n",
    "            col: list[str] = [row[\"距離\"], row[\"コース\"]]\n",
    "            if \"不明\" in col:\n",
    "                continue\n",
    "            rank: str = row[\"着順\"] if int(row[\"着順\"]) <= 3 else \"3<\"\n",
    "            state: str = row[\"馬場\"] if row[\"馬場\"] != \"不明\" else \"良\"\n",
    "            race_type: str = (\n",
    "                \"重賞\" if row[\"レース名\"] in [\"G3\", \"G1\", \"G2\"] else \"非重賞\"\n",
    "            )\n",
    "            col = f'{row[\"開催\"]}_{race_type}_{row[\"距離\"]}_{row[\"コース\"]}_{state}_{rank}'\n",
    "            df_tmp[col] += 1\n",
    "        return df_tmp\n",
    "\n",
    "    @classmethod\n",
    "    def modify(cls, df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df_raw.copy()\n",
    "        df = cls.arrange_result(df)\n",
    "        # 加工\n",
    "        df = df[[\"開催\", \"天気\", \"レース名\", \"着順\", \"距離\", \"馬場\"]]\n",
    "        df = cls.divide_corse(df)\n",
    "        if len(df) > 1:\n",
    "            df[\"開催\"] = df[\"開催\"].map(cls.transform_held)\n",
    "            df[\"レース名\"] = df[\"レース名\"].map(cls.transform_race_name)\n",
    "            df[\"距離\"] = df[\"距離\"].map(cls.transform_race_length)\n",
    "            df[\"着順\"] = df[\"着順\"].map(cls.remove_str)\n",
    "        df = cls.delete_invalid_race(df)\n",
    "        df = df.replace(0, \"不明\")\n",
    "        return df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    @classmethod\n",
    "    def pca_transform(cls, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_transform = cls.pca.transform(df)\n",
    "        return pd.DataFrame(df_transform)\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, path: str) -> pd.DataFrame:\n",
    "        results_raws = cls.read_results(path)\n",
    "        results = []\n",
    "        for i in results_raws:\n",
    "            results_df = cls.modify(i)\n",
    "            results.append(cls.totalling_result(results_df))\n",
    "        result = pd.concat(results, axis=1)\n",
    "        return cls.pca_transform(result)\n",
    "\n",
    "    @classmethod\n",
    "    def process(cls, path: [str] or str) -> pd.DataFrame:\n",
    "        if isinstance(path, list):\n",
    "            results = []\n",
    "            for i in path:\n",
    "                results.append(cls.transform(i))\n",
    "            result = pd.concat(results)\n",
    "            rows = 18 - len(result)\n",
    "            if rows > 0:\n",
    "                result = cls.add_rows(result, rows)\n",
    "            return result\n",
    "        elif isinstance(path, str):\n",
    "            return cls.transform(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過去成績の処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResult(ResultProcessor):\n",
    "    max_column = 10\n",
    "    columns_to_scale = [\"馬体重\", \"増減\", \"斤量\"]\n",
    "    with open(\"../models/horse_result_encoder.pickle\", \"rb\") as f:\n",
    "        encoder: ce.OneHotEncoder = pickle.load(f)\n",
    "    with open(\"../models/horse_results_scaler.pickle\", \"rb\") as f:\n",
    "        scaler: StandardScaler = pickle.load(f)\n",
    "\n",
    "    def select_newer_race(df_raw: pd.DataFrame, date: str) -> pd.DataFrame:\n",
    "        \"\"\"レース日より前の日付の成績を抽出する\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "            date (str): 基準にする日付\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 抽出したデータ\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        df = df[df[\"日付\"] < datetime.datetime.strptime(date, \"%Y年%m月%d日\")]\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def mapping_data(cls, df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"データフレームの各カラムの値に対する一括処理をまとめた関数\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 処理後のデータフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        df[\"日付\"] = df[\"日付\"].map(cls.convert_date)\n",
    "        df[\"開催\"] = df[\"開催\"].map(cls.transform_held)\n",
    "        df[\"レース名\"] = df[\"レース名\"].map(cls.transform_race_name)\n",
    "        df[\"馬番\"] = df[\"馬番\"].map(lambda x: 0 if x > 18 else x)\n",
    "        df[\"着順\"] = df[\"着順\"].map(cls.remove_str)\n",
    "        df[\"馬場\"] = df[\"馬場\"].replace(0, \"不明\")\n",
    "        df[\"天気\"] = df[\"天気\"].replace(0, \"不明\")\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, df_raw: pd.DataFrame, date: str) -> pd.DataFrame:\n",
    "        \"\"\"成績データを変換する\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 成績データ\n",
    "            date (str): 基準の日付。これより前のレース成績だけを扱う\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 変換後データ\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        columns = [\n",
    "            \"賞金\",\n",
    "            \"厩舎ｺﾒﾝﾄ\",\n",
    "            \"備考\",\n",
    "            \"勝ち馬(2着馬)\",\n",
    "            \"着差\",\n",
    "            \"ﾀｲﾑ指数\",\n",
    "            \"通過\",\n",
    "            \"ペース\",\n",
    "            \"上り\",\n",
    "            \"馬場指数\",\n",
    "            \"タイム\",\n",
    "            \"映像\",\n",
    "            \"騎手\",\n",
    "            \"オッズ\",\n",
    "            \"人気\",\n",
    "        ]\n",
    "        df = cls.arrange_result(df)\n",
    "        if date:\n",
    "            df = cls.select_newer_race(df, date)\n",
    "        df = cls.drop_columns(df, columns)\n",
    "        df = cls.divide_horse_weight(df)\n",
    "        df = cls.divide_corse(df)\n",
    "        df = cls.mapping_data(df)\n",
    "        # 型をintにする\n",
    "        df = df.astype({\"R\": int, \"枠番\": int})\n",
    "        # 標準化\n",
    "        df[cls.columns_to_scale] = cls.scaler.transform(df[cls.columns_to_scale])\n",
    "        # ダミー変数化\n",
    "        df = cls.encoder.transform(df)\n",
    "        # 行数の調整\n",
    "        shortage_rows = cls.max_column - len(df)\n",
    "        if shortage_rows > 0:\n",
    "            df = cls.add_rows(df, shortage_rows)\n",
    "        df = df.head(cls.max_column)\n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def process(\n",
    "        cls, path: list[str] | str, date=None\n",
    "    ) -> list[pd.DataFrame] | pd.DataFrame:\n",
    "        \"\"\"成績データが複数かどうかで処理を分けるための関数\n",
    "\n",
    "        Args:\n",
    "            path (list[str]orstr): 成績データのファイルパス\n",
    "            date (_type_, optional): 日付。デフォルトはNone.\n",
    "\n",
    "        Returns:\n",
    "            list[pd.DataFrame] or pd.DataFrame: 変換したデータはデータフレーム単一か、リストに入れて返す\n",
    "        \"\"\"\n",
    "        if isinstance(path, list):\n",
    "            dfs = []\n",
    "            for i in path:\n",
    "                df_raw = cls.read_results(i)\n",
    "                df = df_raw.copy()\n",
    "                df = cls.transform(df, date)\n",
    "                dfs.append(df)\n",
    "            return dfs\n",
    "        else:\n",
    "            df_raw = cls.read_results(path)\n",
    "            df = df_raw.copy()\n",
    "            df = cls.transform(df, date)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レース結果の処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceResults:\n",
    "    \"\"\"レース結果をデータを整形する\"\"\"\n",
    "\n",
    "    with open(\"../models/race_info_encoder.pickle\", \"rb\") as f:\n",
    "        encoder = pickle.load(f)\n",
    "\n",
    "    with open(\"../models/horse_info_scaler.pickle\", \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    def read_df(path: str) -> pd.DataFrame:\n",
    "        \"\"\"データフレームの読み込み\n",
    "\n",
    "        Args:\n",
    "            path (str): pickleのパス\n",
    "\n",
    "        Raises:\n",
    "            TypeError: 引数が文字列でなければエラーを出す\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 読み込んだデータフレーム\n",
    "        \"\"\"\n",
    "        if not isinstance(path, str):\n",
    "            raise TypeError(\n",
    "                f'\"path\" argument is expected to be of type str, got {type(path).__name__} instead'\n",
    "            )\n",
    "        results_processed = pd.read_pickle(path)\n",
    "        return results_processed\n",
    "\n",
    "    def divide_weight_gender(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"性齢の値を性別と年齢に分け、馬体重も体重と増減に分ける。性別はダミー変数化する\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 変換後データフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        gender = df[\"性齢\"].str[0]\n",
    "        df[\"牡\"] = gender.map(lambda x: 1 if x == \"牡\" else 0)\n",
    "        df[\"牝\"] = gender.map(lambda x: 1 if x == \"牝\" else 0)\n",
    "        df[\"セ\"] = gender.map(lambda x: 1 if x == \"セ\" else 0)\n",
    "        df[\"年齢\"] = df[\"性齢\"].str[1:]\n",
    "        df[\"体重\"] = df[\"馬体重\"].replace(\n",
    "            to_replace=r\"(\\d+).*\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "        df[\"増減\"] = df[\"馬体重\"].replace(\n",
    "            to_replace=r\"\\d+\\(\\+{0,1}([-]{0,1}\\d+)\\)\", value=r\"\\1\", regex=True\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def transform_rank(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"着順のデータを３着以内かどうかの値にする。(3着以内であれば1、そうでなければ0)\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 変換後データ\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        df[\"3着以内\"] = df[\"着順\"].apply(\n",
    "            lambda x: 1 if isinstance(x, int) and x <= 3 else 0\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def drop_columns(df_raw: pd.DataFrame, columns: [str]) -> pd.DataFrame:\n",
    "        \"\"\"不要なカラムを削除する\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 対象データフレーム\n",
    "            columns (str]): 削除するカラム名\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 削除後データフレーム\n",
    "        \"\"\"\n",
    "        df = df_raw.drop(columns=columns)\n",
    "        return df\n",
    "\n",
    "    def transform_date(date: str) -> str:\n",
    "        \"\"\"日付を変換して、その年の1月1日からの週数を計算する\n",
    "\n",
    "        Args:\n",
    "            date (str): 日付の文字列（%Y年%m月%d日）\n",
    "\n",
    "        Returns:\n",
    "            str: 変換後の日付文字列\n",
    "        \"\"\"\n",
    "        # 日付の形式を変換\n",
    "        date_converted = datetime.datetime.strptime(date, \"%Y年%m月%d日\")\n",
    "        # その年の1月1日を計算\n",
    "        base_date = datetime.datetime(date_converted.year, 1, 1)\n",
    "        # 週数の差を計算\n",
    "        return (date_converted - base_date).days // 7\n",
    "\n",
    "    def extraction_drop_columns(\n",
    "        df: pd.DataFrame, columns: [str]\n",
    "    ) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"データフレームをカラム指定で分割する\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): 対象のデータフレーム\n",
    "            pd ([str]): 分割するカラム名\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame, pd.DataFrame): 指定したカラムを抽出したデータフレームと、それを取り除いたデータフレーム\n",
    "        \"\"\"\n",
    "        df_extraction = df.loc[:, columns]\n",
    "        df_dropped = df.drop(columns=columns)\n",
    "        return df_extraction, df_dropped\n",
    "\n",
    "    def add_rows(df_raw: pd.DataFrame, rows: int) -> pd.DataFrame:\n",
    "        df = df_raw.copy()\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                df,\n",
    "                pd.DataFrame(np.zeros((rows, len(df.columns))), columns=df.columns),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def adapt_race_info(cls, df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"レース情報の日付をその年の週数に、コースの長さのスケールを1/100にする。データ型も変更する\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): レース情報\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 変換後のデータ\n",
    "        \"\"\"\n",
    "        df = df_raw.loc[[0], :]\n",
    "        df[\"date\"] = cls.transform_date(df.loc[0, \"date\"])\n",
    "        df[\"course_length\"] = float(df.loc[0, \"course_length\"]) / 100\n",
    "        df[\"round\"] = df[\"round\"].astype(float)\n",
    "\n",
    "        df = cls.encoder.transform(df)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def horse_info_transform(cls, df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"出走馬情報の標準化と足りない行の補填、型変換をする\n",
    "\n",
    "        Args:\n",
    "            df_raw (pd.DataFrame): 出走馬情報\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 変換後のデータ\n",
    "        \"\"\"\n",
    "        df = df_raw.copy()\n",
    "        columns_to_scale = [\"体重\", \"増減\"]\n",
    "        df[columns_to_scale] = cls.scaler.transform(df[columns_to_scale])\n",
    "        shortage_rows = 18 - len(df)\n",
    "        df = cls.add_rows(df, shortage_rows)\n",
    "        df[\"年齢\"] = df[\"年齢\"].astype(float)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def make_infos(cls, path: str) -> {pd.DataFrame or str}:\n",
    "        \"\"\"レース結果をレース情報、出走馬情報、出走馬ID、レース日付、正解ラベルの5個に分ける\n",
    "\n",
    "        Args:\n",
    "            path (str): レース結果ファイルのパス\n",
    "\n",
    "        Returns:\n",
    "            {pd.DataFrame or str}: dictで保存。キーはそれぞれrace,horse,ids,date,label。date以外はデータフレーム\n",
    "        \"\"\"\n",
    "        drop_columns = [\n",
    "            \"馬名\",\n",
    "            \"性齢\",\n",
    "            \"騎手\",\n",
    "            \"タイム\",\n",
    "            \"着差\",\n",
    "            \"人気\",\n",
    "            \"調教師\",\n",
    "            \"単勝\",\n",
    "            \"jockey_id\",\n",
    "            \"馬体重\",\n",
    "            \"着順\",\n",
    "        ]\n",
    "        race_info_columns = [\n",
    "            \"date\",\n",
    "            \"round\",\n",
    "            \"course_length\",\n",
    "            \"course_type\",\n",
    "            \"course_way\",\n",
    "            \"weather\",\n",
    "            \"state_grass\",\n",
    "            \"state_dirt\",\n",
    "            \"place\",\n",
    "            \"class\",\n",
    "        ]\n",
    "        df_raw = cls.read_df(path)\n",
    "        df = df_raw.copy()\n",
    "        # データの0埋めを行う\n",
    "        df = df.fillna(0)\n",
    "        # 馬体重のカラムについては「0(0)」で埋める\n",
    "        df[\"馬体重\"].replace(0, \"0(0)\", inplace=True)\n",
    "        df[\"馬体重\"].replace(\"計不\", \"0(0)\", inplace=True)\n",
    "        df = cls.divide_weight_gender(df)\n",
    "        df = cls.transform_rank(df)\n",
    "        df = cls.drop_columns(df, drop_columns)\n",
    "        race_info, horse_info = cls.extraction_drop_columns(df, race_info_columns)\n",
    "        horse_id, horse_info = cls.extraction_drop_columns(horse_info, [\"horse_id\"])\n",
    "\n",
    "        # 標準化等の変換\n",
    "        race_info = cls.adapt_race_info(race_info)\n",
    "        horse_info = cls.horse_info_transform(horse_info)\n",
    "        return {\n",
    "            \"race\": race_info,\n",
    "            \"horse\": horse_info.drop([\"3着以内\"], axis=1),\n",
    "            \"ids\": list(horse_id.iloc[:, 0].values),\n",
    "            \"date\": df_raw.loc[0, \"date\"],\n",
    "            \"label\": horse_info[\"3着以内\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([720])\n",
      "torch.Size([40])\n",
      "torch.Size([162])\n",
      "torch.Size([792])\n"
     ]
    }
   ],
   "source": [
    "# レース結果\n",
    "test = RaceResults.make_infos(\"../Raw-Data/Race-Results/2022/01020607.pkl\")\n",
    "\n",
    "# 親成績\n",
    "test_ped_paths = [f\"../Raw-Data/Pedigree/{i}.pickle\" for i in test[\"ids\"]]\n",
    "test_ped = PedigreeResults.process(test_ped_paths)\n",
    "\n",
    "# 過去成績\n",
    "test_results_paths = [f\"../Raw-Data/Horse-Results/{i}.pkl\" for i in test[\"ids\"]]\n",
    "test_results = HorseResult.process(test_results_paths, test[\"date\"])\n",
    "vae = VAE(\"../models/horse_result_VAE.pth\", \"cpu\")\n",
    "vae_test = vae.process(test_results)\n",
    "vae_len = 18 - len(vae_test)\n",
    "for _ in range(vae_len):\n",
    "    array_zeros = torch.zeros(40)\n",
    "    vae_test.append(array_zeros)\n",
    "vae_test = torch.cat(vae_test)\n",
    "\n",
    "race_array = test[\"race\"].values.flatten()\n",
    "race = torch.tensor(race_array, dtype=torch.float32)\n",
    "horse_array = test[\"horse\"].values.flatten()\n",
    "horse = torch.tensor(horse_array, dtype=torch.float32)\n",
    "ped_array = test_ped.values.flatten()\n",
    "peds = torch.tensor(ped_array, dtype=torch.float32)\n",
    "\"\"\"\n",
    "race:1*40\n",
    "horse:18*9\n",
    "peds:18*44\n",
    "result:1*720 (18*4*10)\n",
    "\"\"\"\n",
    "print(vae_test.size())\n",
    "print(race.size())\n",
    "print(horse.size())\n",
    "print(peds.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習用データセットの作成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモ  \n",
    "入力データの繋ぎ方は  \n",
    "1.レース情報  \n",
    "2.出走馬情報  \n",
    "3.過去成績  \n",
    "4.親成績  \n",
    "の順番でする。各情報を１次元の torch,Tensor 型にして結合する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "162\n",
      "torch.Size([720])\n",
      "792\n",
      "18\n",
      "torch.Size([18])\n",
      "torch.Size([40])\n",
      "torch.Size([162])\n",
      "torch.Size([1512])\n"
     ]
    }
   ],
   "source": [
    "def df_to_tensor_1d(df_raw: pd.DataFrame) -> torch.Tensor:\n",
    "    df = df_raw.copy()\n",
    "    df_array = df.values.flatten()\n",
    "    return torch.tensor(df_array, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def add_tensor(tensors: list[torch.Tensor]) -> torch.Tensor:\n",
    "    tensors_tmp = tensors\n",
    "    add_num = 18 - len(tensors)\n",
    "    for _ in range(add_num):\n",
    "        array_zeros = torch.zeros(40)\n",
    "        tensors_tmp.append(array_zeros)\n",
    "    return torch.cat(tensors_tmp)\n",
    "\n",
    "\n",
    "def make_train_data(path: str):\n",
    "    vae = VAE(\"../models/horse_result_VAE.pth\")\n",
    "    data = RaceResults.make_infos(path)\n",
    "\n",
    "    ped_paths = [f\"../Raw-Data/Pedigree/{i}.pickle\" for i in data[\"ids\"]]\n",
    "    results_paths = [f\"../Raw-Data/Horse-Results/{i}.pkl\" for i in data[\"ids\"]]\n",
    "\n",
    "    ped_raw = PedigreeResults.process(ped_paths)\n",
    "    result_raw = HorseResult.process(results_paths)\n",
    "\n",
    "    vae_raw = vae.process(result_raw)\n",
    "    vae_result = add_tensor(vae_raw)\n",
    "    print(data[\"race\"].size)\n",
    "    print(data[\"horse\"].size)\n",
    "    print(vae_result.size())\n",
    "    print(ped_raw.size)\n",
    "    print(data[\"label\"].size)\n",
    "    race = df_to_tensor_1d(data[\"race\"])\n",
    "    horse = df_to_tensor_1d(data[\"horse\"])\n",
    "    peds = df_to_tensor_1d(ped_raw)\n",
    "    label = df_to_tensor_1d(data[\"label\"])\n",
    "    return {\n",
    "        \"label\": label,  # 正解ラベル\n",
    "        \"race\": race,  # レース情報\n",
    "        \"horse\": horse,  # 出走馬\n",
    "        \"results\": torch.cat([vae_result, peds]),  # 成績\n",
    "    }\n",
    "\n",
    "\n",
    "# レース結果\n",
    "# test = RaceResults.make_infos(\"../Raw-Data/Race-Results/2022/01020607.pkl\")\n",
    "test = make_train_data(\"../Raw-Data/Race-Results/2022/01020607.pkl\")\n",
    "for i in test.values():\n",
    "    if isinstance(i, torch.Tensor):\n",
    "        print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3456/3456 [15:03<00:00,  3.82it/s]   \n"
     ]
    }
   ],
   "source": [
    "def df_to_tensor_1d(df_raw: pd.DataFrame) -> torch.Tensor:\n",
    "    df = df_raw.copy()\n",
    "    df_array = df.values.flatten()\n",
    "    return torch.tensor(df_array, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def add_tensor(tensors: list[torch.Tensor]) -> torch.Tensor:\n",
    "    tensors_tmp = tensors\n",
    "    add_num = 18 - len(tensors)\n",
    "    for _ in range(add_num):\n",
    "        array_zeros = torch.zeros(40)\n",
    "        tensors_tmp.append(array_zeros)\n",
    "    return torch.cat(tensors_tmp)\n",
    "\n",
    "\n",
    "def make_train_data(path: str):\n",
    "    vae = VAE(\"../models/horse_result_VAE.pth\")\n",
    "    data = RaceResults.make_infos(path)\n",
    "\n",
    "    ped_paths = [f\"../Raw-Data/Pedigree/{i}.pickle\" for i in data[\"ids\"]]\n",
    "    results_paths = [f\"../Raw-Data/Horse-Results/{i}.pkl\" for i in data[\"ids\"]]\n",
    "\n",
    "    ped_raw = PedigreeResults.process(ped_paths)\n",
    "    result_raw = HorseResult.process(results_paths)\n",
    "\n",
    "    vae_raw = vae.process(result_raw)\n",
    "    vae_result = add_tensor(vae_raw)\n",
    "\n",
    "    race = df_to_tensor_1d(data[\"race\"])\n",
    "    horse = df_to_tensor_1d(data[\"horse\"])\n",
    "    peds = df_to_tensor_1d(ped_raw)\n",
    "    label = df_to_tensor_1d(data[\"label\"])\n",
    "    return {\n",
    "        \"label\": label,  # 正解ラベル\n",
    "        \"race\": race,  # レース情報\n",
    "        \"horse\": horse,  # 出走馬\n",
    "        \"results\": torch.cat([vae_result, peds]),  # 成績\n",
    "    }\n",
    "\n",
    "\n",
    "def save_pickle(path: str, data) -> None:\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "results_path = \"../Raw-Data/Race-Results/2022/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "for i in tqdm(dir_list):\n",
    "    try:\n",
    "        save_file_name = i.replace(\".pkl\", \"\")\n",
    "        save_path = f\"../Processed-Data/Race-Results/{save_file_name}.pickle\"\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        result_path = f\"{results_path}{i}\"\n",
    "        result_processed = make_train_data(result_path)\n",
    "        save_pickle(save_path, result_processed)\n",
    "    except Exception as e:\n",
    "        print(i)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1714])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"../Processed-Data/Race-Results/01010101.pickle\"\n",
    "with open(test, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "data\n",
    "t = torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]])\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3456 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3456/3456 [00:01<00:00, 2998.37it/s]\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../Processed-Data/Race-Results/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "data_set = []\n",
    "for i in tqdm(dir_list):\n",
    "    path = f\"../Processed-Data/Race-Results/{i}\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    data_modify = {\n",
    "        \"data\": torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]]),\n",
    "        \"label\": data[\"label\"],\n",
    "    }\n",
    "    data_set.append(data_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([29.,  1., 18.,  ...,  0.,  0.,  0.]),\n",
       " 'label': tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習モデル作成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットクラス\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, data, is_file=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list of str): 学習用データファイルのパスのリスト\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.file = is_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.file:\n",
    "            file_path = self.data[idx]\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            inputs = torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]])\n",
    "            labels = data[\"label\"]\n",
    "            return inputs, labels\n",
    "        else:\n",
    "            data_set = self.data[idx]\n",
    "            return data_set[\"data\"], data_set[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.fc_in = nn.Linear(input_size, 1024)  # 入力層から隠れ層へ\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc_act = nn.Mish()\n",
    "        self.fc_sig = nn.Sigmoid()\n",
    "        self.fc_out = nn.Linear(1024, output_size)  # 隠れ層から出力層へ\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc_in(x)\n",
    "        out = self.fc_act(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc_act(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc_act(out)\n",
    "        out = self.fc_out(out)\n",
    "        out = self.fc_sig(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの用意\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:2419\n",
      "val:518\n",
      "test:519\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# ファイルで学習させるとき\n",
    "results_path = \"../Processed-Data/Race-Results/\"\n",
    "dir_list_raw = os.listdir(results_path)\n",
    "dir_list = list(map(lambda x: f\"../Processed-Data/Race-Results/{x}\", dir_list_raw))\n",
    "dataset = CustomDataSet(dir_list, is_file=True)\n",
    "\n",
    "\"\"\"\n",
    "results_path = \"../Processed-Data/Race-Results/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "data_set = []\n",
    "for i in tqdm(dir_list):\n",
    "    path = f\"../Processed-Data/Race-Results/{i}\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    data_modify = {\n",
    "        \"data\": torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]]),\n",
    "        \"label\": data[\"label\"],\n",
    "    }\n",
    "    data_set.append(data_modify)\n",
    "dataset = CustomDataSet(dir_list)\n",
    "\"\"\"\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "# 分割比率を設定 (例: 訓練:検証:テスト = 70%:15%:15%)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "val_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size - train_size - val_size  # 残りをテストセットとする\n",
    "\n",
    "print(f\"train:{train_size}\")\n",
    "print(f\"val:{val_size}\")\n",
    "print(f\"test:{test_size}\")\n",
    "\n",
    "# データセットをランダムに分割\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "batch = 64\n",
    "# DataLoaderを作成\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの用意\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1.0):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # ラベルが1の要素に対して指定された重みを適用\n",
    "        weights = torch.ones_like(targets) * self.pos_weight\n",
    "        weights[targets == 0] = 1.0\n",
    "        # 重み付きバイナリクロスエントロピー損失の計算\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets, weight=weights)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# 1714\n",
    "\n",
    "\n",
    "model = NNClassifier(1714, 18).to(device)\n",
    "\n",
    "\n",
    "\n",
    "criterion = WeightedBCELoss(pos_weight=6.0)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]  Loss1.2255194187164307  Accuracy: 23.04%\n",
      "Epoch [10/50]  Loss1.1354992389678955  Accuracy: 25.56%\n",
      "Epoch [15/50]  Loss1.1959128379821777  Accuracy: 25.21%\n",
      "Epoch [20/50]  Loss1.1577461957931519  Accuracy: 27.03%\n",
      "Epoch [25/50]  Loss1.12587571144104  Accuracy: 26.19%\n",
      "Epoch [30/50]  Loss1.157365083694458  Accuracy: 28.08%\n",
      "Epoch [35/50]  Loss1.0958878993988037  Accuracy: 28.57%\n",
      "Epoch [40/50]  Loss1.1195775270462036  Accuracy: 28.92%\n",
      "Epoch [45/50]  Loss1.0984946489334106  Accuracy: 30.60%\n",
      "Epoch [50/50]  Loss1.0982002019882202  Accuracy: 30.88%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy_topk(loader, model, k=3):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            # 上位k個の予測を1に、それ以外を0にする\n",
    "            topk_predictions = torch.zeros_like(scores, device=device)\n",
    "            topk_vals, topk_indices = scores.topk(k, dim=1)\n",
    "            # 上位k個の位置に1を設定\n",
    "            topk_predictions.scatter_(1, topk_indices, 1)\n",
    "\n",
    "            # yが1の値の時のみを考慮するために、topk_predictionsとyの論理ANDを取る\n",
    "            correct_predictions = topk_predictions.bool() & y.bool()\n",
    "            # 正解のカウント（yが1の場合のみ）\n",
    "            num_correct += correct_predictions.type(torch.float).sum().item()\n",
    "            # yが1の値の総数をカウント\n",
    "            num_samples += y.sum().item()\n",
    "\n",
    "        # 正解率の計算（yが1の場合のみに基づく）\n",
    "        accuracy = (num_correct / num_samples * 100) if num_samples > 0 else 0\n",
    "    model.train()\n",
    "    return f\"Accuracy: {accuracy:.2f}%\"\n",
    "\n",
    "\n",
    "num_epochs = 50  # エポック数\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        x = data.to(device)\n",
    "        y = targets.to(device)\n",
    "        scores = model(x)\n",
    "        loss = criterion(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}]  Loss{loss}  {check_accuracy_topk(val_loader, model)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            scores = model(x, mask=None)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Accuracy: {float(num_correct)/float(num_samples)*100:.2f}%\")\n",
    "\n",
    "    model.train()  # モデルを訓練モードに戻す\n",
    "\n",
    "\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 値分類バージョン\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 2., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 3., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 4., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 5., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 6., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 7., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 8., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([ 9., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([10., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([11., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([12., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([13., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([14., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([15., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([16., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([17., 29.,  1.,  ...,  0.,  0.,  0.])\n",
      "tensor([18., 29.,  1.,  ...,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "test = \"../Processed-Data/Race-Results/01010101.pickle\"\n",
    "with open(test, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "data\n",
    "t = torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]])\n",
    "data[\"label\"]\n",
    "count = 1\n",
    "for i in data[\"label\"]:\n",
    "    horse_num = torch.Tensor([count % 19])\n",
    "    count += 1\n",
    "    print(torch.cat([horse_num, t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3456/3456 [00:53<00:00, 65.03it/s]\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../Processed-Data/Race-Results/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "count = 1\n",
    "for i in tqdm(dir_list):\n",
    "    raw_path = f\"../Processed-Data/Race-Results/{i}\"\n",
    "    with open(raw_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    static_data = torch.cat([data[\"race\"], data[\"horse\"], data[\"results\"]])\n",
    "    for i in data[\"label\"]:\n",
    "        horse_num = torch.Tensor([count % 19])\n",
    "        new_data = {\"input\": torch.cat([horse_num, static_data]), \"label\": i}\n",
    "        with open(\n",
    "            f\"../Processed-Data/Race-Results-one-output/{count}.pickle\", \"wb\"\n",
    "        ) as f:\n",
    "            pickle.dump(new_data, f)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットクラス\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list of str): 学習用データファイルのパスのリスト\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data[idx]\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data[\"input\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc_in = nn.Linear(input_size, 1024)  # 入力層から隠れ層へ\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc_act = nn.Mish()\n",
    "        self.fc_sig = nn.Sigmoid()\n",
    "        self.fc_out = nn.Linear(1024, output_size)  # 隠れ層から出力層へ\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc_in(x)\n",
    "        out = self.fc_act(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc_act(out)\n",
    "        out = self.fc_out(out)\n",
    "        out = self.fc_sig(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1715])\n",
      "tensor(1.)\n",
      "train:43545\n",
      "val:9331\n",
      "test:9332\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../Processed-Data/Race-Results-one-output/\"\n",
    "dir_list = os.listdir(results_path)\n",
    "file_list = list(map(lambda x: f\"{results_path}{x}\", dir_list))\n",
    "dataset = CustomDataSet(file_list)\n",
    "print(dataset[0][0].size())\n",
    "print(dataset[0][1])\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "# 分割比率を設定 (例: 訓練:検証:テスト = 70%:15%:15%)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "val_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size - train_size - val_size  # 残りをテストセットとする\n",
    "\n",
    "print(f\"train:{train_size}\")\n",
    "print(f\"val:{val_size}\")\n",
    "print(f\"test:{test_size}\")\n",
    "\n",
    "# データセットをランダムに分割\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "batch = 64\n",
    "# DataLoaderを作成\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=6):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # ラベルが1の要素に対して指定された重みを適用\n",
    "        weight = target * self.pos_weight + (1.0 - target)\n",
    "        loss = nn.functional.binary_cross_entropy(input, target, weight=weight)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# 1714\n",
    "model = NN(1715, 1).to(device)\n",
    "\n",
    "criterion = WeightedBCELoss(pos_weight=6)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]  Loss: 1.1987590789794922, Total Val Accuracy: 0.18549807369709015, Label 1 Val Accuracy: 0.9717885851860046\n",
      "Epoch [10/25]  Loss: 1.5290355682373047, Total Val Accuracy: 0.368990033864975, Label 1 Val Accuracy: 0.5739591121673584\n",
      "Epoch [15/25]  Loss: 1.024174690246582, Total Val Accuracy: 0.28751805424690247, Label 1 Val Accuracy: 0.7172467708587646\n",
      "Epoch [20/25]  Loss: 1.3569706678390503, Total Val Accuracy: 0.3459533452987671, Label 1 Val Accuracy: 0.5355780720710754\n",
      "Epoch [25/25]  Loss: 1.1005702018737793, Total Val Accuracy: 0.4014424681663513, Label 1 Val Accuracy: 0.3859107494354248\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(scores, targets):\n",
    "    # スコアが0.5以上のものを1と予測\n",
    "    predictions = scores >= 0.5\n",
    "    correct = (predictions == targets).float()  # 正解の予測\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_accuracy_for_label_one(scores, targets):\n",
    "    # ラベルが1のデータのみを抽出\n",
    "    mask = targets == 1\n",
    "    correct = ((scores >= 0.5) == targets)[mask].float()  # 正解の予測\n",
    "    accuracy = correct.sum() / len(correct) if len(correct) > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    with torch.no_grad():\n",
    "        total_accuracy = 0\n",
    "        label_one_accuracy = 0\n",
    "        num_samples = 0\n",
    "        for data, targets in loader:\n",
    "            x = data.to(device)\n",
    "            y = targets.unsqueeze(1).to(device)\n",
    "            scores = model(x)\n",
    "            total_accuracy += calculate_accuracy(scores, y)\n",
    "            label_one_accuracy += calculate_accuracy_for_label_one(scores, y)\n",
    "            num_samples += 1\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {loss.item()}, Total Val Accuracy: {total_accuracy / num_samples}, Label 1 Val Accuracy: {label_one_accuracy / num_samples}\"\n",
    "        )\n",
    "    model.train()  # モデルを訓練モードに戻す\n",
    "\n",
    "\n",
    "num_epochs = 25  # エポック数\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        x = data.to(device)\n",
    "        y = targets.unsqueeze(1).to(device)\n",
    "        scores = model(x)\n",
    "        loss = criterion(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        test(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
